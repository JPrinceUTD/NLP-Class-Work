{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Portfolio Assignment WordNet\n",
        "\n",
        "By Jibin Prince"
      ],
      "metadata": {
        "id": "ukurDfQqcWfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "#nltk.download('all')\n",
        "from nltk.corpus import wordnet as wn, sentiwordnet as swn\n",
        "from nltk.wsd import lesk\n",
        "from nltk import word_tokenize\n",
        "from nltk.book import *\n",
        "import math"
      ],
      "metadata": {
        "id": "5CAVhuXNiqd9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet Summary (Instruction 1)\n",
        "\n",
        "WordNet is a large lexical database of English words and their sematic relations to each other. These semantic relations form a unique network to help NLP processes find relationship between words. In WordNet, nouns, verbs, adjectives, and adverbs are grouped into sets of synonyms, which are known as synsets.\n",
        "\n",
        "Reference: L. Williams, “WordNet: A Lexical Taxonomy of English Words,” Medium, Jan. 27, 2021. https://towardsdatascience.com/%EF%B8%8Fwordnet-a-lexical-taxonomy-of-english-words-4373b541cfff"
      ],
      "metadata": {
        "id": "cRer45JAbWUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction 2\n",
        "wn.synsets('person')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yJxqZBZNhtl5",
        "outputId": "1327597a-818e-4c00-d111-7eee9130c771"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('person.n.01'), Synset('person.n.02'), Synset('person.n.03')]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction 3\n",
        "print(\"Synset: person.n.02\")\n",
        "person = wn.synset('person.n.02')\n",
        "print(\"Definition: \" + person.definition())\n",
        "print(\"Usage Examples: \")\n",
        "print(person.examples())\n",
        "print(\"Lemmas: \")\n",
        "print(person.lemmas())\n",
        "print()\n",
        "print(\"Synset: person.n.02 Hierarchy\")\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(person.closure(hyper))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CS1YRJIpkaQ3",
        "outputId": "1c67cb91-c1bc-4acd-fa34-8d2cd3af23b7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: person.n.02\n",
            "Definition: a human body (usually including the clothing)\n",
            "Usage Examples: \n",
            "['a weapon was hidden on his person']\n",
            "Lemmas: \n",
            "[Lemma('person.n.02.person')]\n",
            "\n",
            "Synset: person.n.02 Hierarchy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('human_body.n.01'),\n",
              " Synset('body.n.01'),\n",
              " Synset('natural_object.n.01'),\n",
              " Synset('whole.n.02'),\n",
              " Synset('object.n.01'),\n",
              " Synset('physical_entity.n.01'),\n",
              " Synset('entity.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For nouns, it looks like there is a hierarchy of hypernyms that a noun can reach with entity.n.01 being the top-most level of the noun hierarchy. It is interesting that entity is above object and it makes sense to me since an entity of an object means the object has an independent existence."
      ],
      "metadata": {
        "id": "USAGUckocBdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction 4\n",
        "print(\"Synset: person.n.02\")\n",
        "print(\"Hypernyms: \")\n",
        "print(person.hypernyms())\n",
        "print(\"Hyponyms: \")\n",
        "print(person.hyponyms())\n",
        "print(\"Meronyms: \")\n",
        "print(person.part_meronyms() + person.substance_meronyms())\n",
        "print(\"Holonyms: \")\n",
        "print(person.part_holonyms() + person.substance_holonyms())\n",
        "print(\"Antonyms: \")\n",
        "print(person.lemmas()[0].antonyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ISyqg-_To98E",
        "outputId": "cc99538c-3847-45b8-8960-8be21d714731"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: person.n.02\n",
            "Hypernyms: \n",
            "[Synset('human_body.n.01')]\n",
            "Hyponyms: \n",
            "[]\n",
            "Meronyms: \n",
            "[]\n",
            "Holonyms: \n",
            "[]\n",
            "Antonyms: \n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction 5\n",
        "wn.synsets(\"try\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iwikywf7rKqu",
        "outputId": "fd142a18-dd5a-4139-de85-78768bd68485"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('attempt.n.01'),\n",
              " Synset('try.v.01'),\n",
              " Synset('test.v.01'),\n",
              " Synset('judge.v.05'),\n",
              " Synset('sample.v.01'),\n",
              " Synset('hear.v.03'),\n",
              " Synset('try.v.06'),\n",
              " Synset('try.v.07'),\n",
              " Synset('try.v.08'),\n",
              " Synset('try_on.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction 6\n",
        "print(\"Synset: try.v.01\")\n",
        "tryVerb = wn.synset('try.v.01')\n",
        "print(\"Definition: \" + tryVerb.definition())\n",
        "print(\"Usage Examples: \")\n",
        "print(tryVerb.examples())\n",
        "print(\"Lemmas: \")\n",
        "print(tryVerb.lemmas())\n",
        "print()\n",
        "print(\"Synset: try.v.01 Hierarchy\")\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(tryVerb.closure(hyper))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "W-IqFmzdr-or",
        "outputId": "d2144bcb-fc7b-4bea-e4b4-dc43ca2d0b52"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: try.v.01\n",
            "Definition: make an effort or attempt\n",
            "Usage Examples: \n",
            "['He tried to shake off his fears', 'The infant had essayed a few wobbly steps', 'The police attempted to stop the thief', 'He sought to improve himself', 'She always seeks to do good in the world']\n",
            "Lemmas: \n",
            "[Lemma('try.v.01.try'), Lemma('try.v.01.seek'), Lemma('try.v.01.attempt'), Lemma('try.v.01.essay'), Lemma('try.v.01.assay')]\n",
            "\n",
            "Synset: try.v.01 Hierarchy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('act.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike nouns, for verbs, there is no similar top-level hierarchy. For verbs, the top-most verb in the hierarchy can be different for each verb."
      ],
      "metadata": {
        "id": "cujTv4WBc5y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction 7\n",
        "print(\"Adjective: \")\n",
        "print(wn.morphy(\"outstanding\", wn.ADJ))\n",
        "print(\"Verb: \")\n",
        "print(wn.morphy(\"outstanding\", wn.VERB))\n",
        "print(\"Noun: \")\n",
        "print(wn.morphy(\"outstanding\", wn.NOUN))\n",
        "print(\"Adverb: \")\n",
        "print(wn.morphy(\"outstanding\", wn.ADV))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LYEYNh1-tf0i",
        "outputId": "bb04f357-099f-41ee-9757-5354d7d6942f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjective: \n",
            "outstanding\n",
            "Verb: \n",
            "None\n",
            "Noun: \n",
            "None\n",
            "Adverb: \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction 8\n",
        "print(wn.synsets(\"travel\"))\n",
        "print(wn.synsets(\"walk\"))\n",
        "print()\n",
        "travel = wn.synset(\"travel.v.01\")\n",
        "print(\"Travel def: \" + travel.definition())\n",
        "walk = wn.synset(\"walk.v.01\")\n",
        "print(\"Walk def: \"+ walk.definition())\n",
        "print()\n",
        "print(\"Wu-Palmer Similarity Metric: \" + str(wn.wup_similarity(travel, walk)))\n",
        "print()\n",
        "print(\"Lesk Algorithm: \")\n",
        "travel_tokens = word_tokenize(\"I traveled to the bank.\")\n",
        "walk_tokens = word_tokenize(\"I walked to the bank.\")\n",
        "print(lesk(travel_tokens, \"travel\", \"v\"))\n",
        "print(lesk(walk_tokens, \"walk\", \"v\"))\n",
        "print()\n",
        "print(\"Travel.v.06 Def: \" + wn.synset('travel.v.06').definition())\n",
        "print(\"Walk.v.05 Def: \" + wn.synset('walk.v.05').definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Gv8md_jduHlM",
        "outputId": "e2e4f316-4fff-494d-845b-982bbbbdc7e6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('travel.n.01'), Synset('change_of_location.n.01'), Synset('locomotion.n.02'), Synset('travel.v.01'), Synset('travel.v.02'), Synset('travel.v.03'), Synset('travel.v.04'), Synset('travel.v.05'), Synset('travel.v.06')]\n",
            "[Synset('walk.n.01'), Synset('base_on_balls.n.01'), Synset('walk.n.03'), Synset('walk.n.04'), Synset('walk.n.05'), Synset('walk.n.06'), Synset('walk_of_life.n.01'), Synset('walk.v.01'), Synset('walk.v.02'), Synset('walk.v.03'), Synset('walk.v.04'), Synset('walk.v.05'), Synset('walk.v.06'), Synset('walk.v.07'), Synset('walk.v.08'), Synset('walk.v.09'), Synset('walk.v.10')]\n",
            "\n",
            "Travel def: change location; move, travel, or proceed, also metaphorically\n",
            "Walk def: use one's feet to advance; advance by steps\n",
            "\n",
            "Wu-Palmer Similarity Metric: 0.6666666666666666\n",
            "\n",
            "Lesk Algorithm: \n",
            "Synset('travel.v.06')\n",
            "Synset('walk.v.05')\n",
            "\n",
            "Travel.v.06 Def: travel from place to place, as for the purpose of finding work, preaching, or acting as a judge\n",
            "Walk.v.05 Def: give a base on balls to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wu-Palmer similarity metric did a fair good job of judging how similar travel.v.01 and walk.v.01, since both definitions are fairly similar in that they mean to move forward, but not exactly the same since travel.v.01 means to change location while walk.v.01 means to advance by steps. Lesk algorithm did worse than Wu-Palmer when using the travel and walk verbs since when they were used interchangeably in the same sentence, the algorithm outputted synset of both verbs with completely and unrelated (in the case of walk) meanings."
      ],
      "metadata": {
        "id": "Zo0mL4hidBBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruction 9\n",
        "\n",
        "SentiWordNet is built on top on WordNet that gives 3 sentiment scores for each synset: positivity, negativity, objectivity. Possible use cases of this resource can be to help determine what the person saying the word feels, or to help generate an appropriate response based on the emotional state of the conversation."
      ],
      "metadata": {
        "id": "VdQ2tuLodLGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exacerbate = swn.senti_synset('exacerbate.v.02')\n",
        "print(\"Def: \" + wn.synset('exacerbate.v.02').definition())\n",
        "print(\"Senti-synsets:\")\n",
        "print(exacerbate)\n",
        "print(\"Positive score: \" + str(exacerbate.pos_score()))\n",
        "print(\"Negative score: \" + str(exacerbate.neg_score()))\n",
        "print(\"Objective score: \" + str(exacerbate.obj_score()))\n",
        "print()\n",
        "print(\"Polarity of each word in sentence:\")\n",
        "sentence = \"the high cost of living only exacerbated the problem\"\n",
        "print(sentence)\n",
        "tokens = sentence.split()\n",
        "for token in tokens:\n",
        "  syn_list = list(swn.senti_synsets(token))\n",
        "  if syn_list:\n",
        "    syn = syn_list[0]\n",
        "    print(token + \": \" + \"Positive score = \" + str(syn.pos_score()) + \", Negative score = \" + str(syn.neg_score()) + \", Objective score = \" + str(syn.obj_score()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w7NNEMSqz2Xw",
        "outputId": "361c49f3-466c-4b9d-fdc6-508d889bc853"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Def: exasperate or irritate\n",
            "Senti-synsets:\n",
            "<exacerbate.v.02: PosScore=0.0 NegScore=0.0>\n",
            "Positive score: 0.0\n",
            "Negative score: 0.0\n",
            "Objective score: 1.0\n",
            "\n",
            "Polarity of each word in sentence:\n",
            "the high cost of living only exacerbated the problem\n",
            "high: Positive score = 0.125, Negative score = 0.0, Objective score = 0.875\n",
            "cost: Positive score = 0.0, Negative score = 0.0, Objective score = 1.0\n",
            "living: Positive score = 0.0, Negative score = 0.0, Objective score = 1.0\n",
            "only: Positive score = 0.0, Negative score = 0.0, Objective score = 1.0\n",
            "exacerbated: Positive score = 0.0, Negative score = 0.25, Objective score = 0.75\n",
            "problem: Positive score = 0.0, Negative score = 0.625, Objective score = 0.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like most of the words in this sentence is deemed highly objective. Once exacerbate was made into past tense, the negativity score increased. A possible utility of knowing these scores in an NLP application could be to have a simple determination of the polarity of a sentence."
      ],
      "metadata": {
        "id": "2s9kjntDdUou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruction 10\n",
        "\n",
        "Basically, a collocation is a sequence of words that appear together more often than what would be expected. An indication is that you cannot substitute synonyms in a collocation."
      ],
      "metadata": {
        "id": "qrClieAtdZF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text4 Collocations:\")\n",
        "text4.collocations()\n",
        "print()\n",
        "print(\"Mutual information of 'United States'\")\n",
        "vocab = len(set(text4))\n",
        "text = ' '.join(text4.tokens)\n",
        "us = text.count('United States') / vocab\n",
        "print(\"p(United States) = \" + str(us))\n",
        "u = text.count('United') / vocab\n",
        "print(\"p(United) = \" + str(u))\n",
        "s = text.count('States') / vocab\n",
        "print(\"p(States) = \" + str(s))\n",
        "pmi = math.log2(us / (u * s))\n",
        "print(\"pmi of United States = \" + str(pmi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OQlGhbdg6aCJ",
        "outputId": "7f97fb3f-7f13-4c1d-cf01-4b4e65027f91"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text4 Collocations:\n",
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n",
            "\n",
            "Mutual information of 'United States'\n",
            "p(United States) = 0.015860349127182045\n",
            "p(United) = 0.0170573566084788\n",
            "p(States) = 0.03301745635910224\n",
            "pmi of United States = 4.815657649820885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of the mutual information formula for 'United States' is around 4.8. This indicates that 'United States' is likely a collocation since the result is positive. Before attempting this calculation, I was initially think that the result would be higher since according to the chapter notes 'fellow citizens' got a pmi of 8.2 and text4 is the inaugural corpus and the phrase 'United States' would be used very frequently."
      ],
      "metadata": {
        "id": "YIZnN-Mydgd6"
      }
    }
  ]
}